"sum(kube_node_status_condition{condition=\"Ready\",status=\"true\"})",
"sum(kube_node_status_condition{condition=\"Ready\",status=\"true\"})",
"sum by (node) (kube_node_status_condition{condition=\"Ready\",status=\"true\"})",
"sum(kube_node_status_allocatable{node=~\"$node\",resource=\"cpu\"})",
"sum(kube_node_status_allocatable{node=~\"$node\",resource=\"memory\"})",
"sum(kube_node_status_allocatable{node=~\"$node\",resource=\"nvidia_com_gpu\"})",
"sum(kube_node_status_allocatable{node=~\"$node\", resource=\"cpu\"} * on (node) kube_node_status_condition{condition=\"Ready\",status=\"true\"})",
"sum(kube_node_status_allocatable{node=~\"$node\", resource=\"memory\"} * on (node) kube_node_status_condition{condition=\"Ready\",status=\"true\"})",
"sum(kube_node_status_allocatable{node=~\"$node\", resource=\"nvidia_com_gpu\"} * on (node) kube_node_status_condition{condition=\"Ready\",status=\"true\"})",
"sum(kube_pod_container_resource_limits{node=~\"$node\",resource=\"cpu\"})",
"sum(kube_pod_container_resource_limits{node=~\"$node\",resource=\"memory\"})",
"sum(kube_node_status_allocatable{node=~\"$node\", resource=\"nvidia_com_gpu\"} * on (node) kube_node_status_condition{condition=\"Ready\",status=\"true\"})",
"sum(kube_pod_container_resource_requests{node=~\"$node\",resource=\"cpu\"})",
"sum(kube_pod_container_resource_requests{node=~\"$node\",resource=\"memory\"})",
"sum(kube_pod_container_resource_requests{node=~\"$node\",resource=\"nvidia_com_gpu\"})",
"sum(kube_pod_container_resource_requests{node=~\"$node\",resource=\"cpu\"})/sum(kube_node_status_allocatable{node=~\"$node\",resource=\"cpu\"})*100",
"sum(kube_pod_container_resource_requests{node=~\"$node\",resource=\"memory\"})/sum(kube_node_status_allocatable{node=~\"$node\",resource=\"memory\"})*100",
"sum(kube_pod_container_resource_requests{node=~\"$node\",resource=\"nvidia_com_gpu\"})/sum(kube_node_status_allocatable{node=~\"$node\",resource=\"nvidia_com_gpu\"})*100",
"sum(kube_pod_container_resource_requests{node=~\"$node\",resource=\"cpu\"})/sum(kube_node_status_allocatable{node=~\"$node\",resource=\"cpu\"})*100",
"sum(kube_node_status_allocatable{node=~\"$node\", resource=\"cpu\"} * on (node) kube_node_status_condition{condition=\"Ready\",status=\"true\"})/sum(kube_node_status_allocatable{node=~\"$node\",resource=\"cpu\"})*100",
"sum(kube_pod_container_resource_requests{node=~\"$node\",resource=\"memory\"})/sum(kube_node_status_allocatable{node=~\"$node\",resource=\"memory\"})*100",
"sum(kube_node_status_allocatable{node=~\"$node\", resource=\"memory\"} * on (node) kube_node_status_condition{condition=\"Ready\",status=\"true\"})/sum(kube_node_status_allocatable{node=~\"$node\",resource=\"memory\"})*100",
"sum(kube_pod_container_resource_requests{node=~\"$node\",resource=\"nvidia_com_gpu\"})/sum(kube_node_status_allocatable{node=~\"$node\",resource=\"nvidia_com_gpu\"})*100",
"sum(kube_node_status_allocatable{node=~\"$node\", resource=\"nvidia_com_gpu\"} * on (node) kube_node_status_condition{condition=\"Ready\",status=\"true\"})/sum(kube_node_status_allocatable{node=~\"$node\",resource=\"nvidia_com_gpu\"})*100",
"count(count by (pod) (kube_pod_container_resource_requests))",
"count(sum_over_time(sum(kube_pod_status_phase{phase=\"Pending\"}) by (pod) [5m:60s]) >= 5)",
"sum by (resource) (kube_pod_container_resource_requests * on(pod) group_left clamp_min(sum_over_time(sum(kube_pod_status_phase{phase='Pending'}) by (pod) [5m:60s]) >= 5, 1)/5)",
